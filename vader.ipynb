{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05480fc-e0e4-4730-bb3b-cc22926d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "# https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8e64f4-a4a0-4c21-86ac-2c69c93ad71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd61451-4f3b-4d51-9112-7cf76a9f0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4afdb07-c57f-474e-ac51-7694fb74385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"part_1.txt\") as transcript:\n",
    "    lines = transcript.readlines()\n",
    "lines_clean = clean(lines[0])\n",
    "ngram_object = TextBlob(lines_clean)\n",
    "ngrams = ngram_object.ngrams(n=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee166a06-358c-4fd3-90ae-5214bebe7a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: Okay I m starting 0.2263\n",
      "Negative: a little bit intimidating -0.3862\n",
      "Negative: little bit intimidating for -0.3862\n",
      "Negative: bit intimidating for me -0.4404\n",
      "Negative: intimidating for me I -0.4404\n",
      "Positive: me I m sure 0.3182\n",
      "Positive: I m sure it 0.3182\n",
      "Positive: m sure it s 0.3182\n",
      "Positive: sure it s fine 0.4767\n",
      "Positive: it s fine and 0.2023\n",
      "Positive: s fine and then 0.2023\n",
      "Positive: fine and then I 0.2023\n",
      "Positive: cookies I m fine 0.2023\n",
      "Positive: I m fine with 0.2023\n",
      "Positive: m fine with those 0.2023\n",
      "Positive: fine with those Okay 0.4019\n",
      "Positive: with those Okay Coronavirus 0.2263\n",
      "Positive: those Okay Coronavirus in 0.2263\n",
      "Positive: Okay Coronavirus in the 0.2263\n",
      "Positive: Slovak Republic very cool 0.3804\n",
      "Positive: Republic very cool I 0.3804\n",
      "Positive: very cool I like 0.6549\n",
      "Positive: cool I like how 0.5859\n",
      "Positive: I like how it 0.3612\n",
      "Positive: like how it has 0.3612\n"
     ]
    }
   ],
   "source": [
    "for ngram in ngrams:\n",
    "    ngram_str = ' '.join(ngram)\n",
    "    sentiment = analyzer.polarity_scores(ngram_str)\n",
    "    if sentiment['compound'] < 0:\n",
    "        print('Negative: ' + ngram_str + ' ' + str(sentiment['compound']))\n",
    "    if sentiment['compound'] > 0:\n",
    "        print('Positive: ' + ngram_str + ' ' + str(sentiment['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e4f2d3-da0e-4f89-879e-fab3662f677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.225, 'neu': 0.775, 'pos': 0.0, 'compound': -0.4927}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.6369}\n",
      "{'neg': 0.627, 'neu': 0.373, 'pos': 0.0, 'compound': -0.5216}\n",
      "{'neg': 0.771, 'neu': 0.229, 'pos': 0.0, 'compound': -0.5216}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.639, 'pos': 0.361, 'compound': 0.3089}\n",
      "{'neg': 0.0, 'neu': 0.633, 'pos': 0.367, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sentiment = analyzer.polarity_scores(\"It was very problematic, I wasn't able to find it at all\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"best\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"not the best\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"not best\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"confident\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"it was not a problem\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"The acting was good , but the movie could have been better\")\n",
    "print(sentiment)\n",
    "\n",
    "sentiment = analyzer.polarity_scores(\"information looks outdated\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3cfd60-1f23-4b55-8203-95bf3c0fc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compound (computed by normalizing the scores above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63491e47-766d-4e8a-8c30-8760d707514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a648d288-dd39-4182-bf7a-7b6be5ccdc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sentiment = analyzer.polarity_scores(\"I don't know\")\n",
    "print(sentiment)\n",
    "# could artificially modify polarity of see\n",
    "sentiment = analyzer.polarity_scores(\"not know\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6455f4f9-425f-464d-84b6-4ec15f59dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = {\n",
    "    'see': 2.0,\n",
    "    'find': 2.0,\n",
    "}\n",
    "\n",
    "analyzer.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35892c98-7da0-49ff-a6de-ba3eadff3d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.713, 'neu': 0.287, 'pos': 0.0, 'compound': -0.357}\n"
     ]
    }
   ],
   "source": [
    "sentiment = analyzer.polarity_scores(\"not find\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbc2c7-e5bb-4606-b6dc-cdd77912fa97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
